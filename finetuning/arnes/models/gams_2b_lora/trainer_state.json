{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3934770253136886,
  "eval_steps": 500,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004371966947929874,
      "grad_norm": 1.7411335706710815,
      "learning_rate": 3.6800000000000003e-06,
      "loss": 1.71,
      "step": 100
    },
    {
      "epoch": 0.008743933895859748,
      "grad_norm": 2.9930498600006104,
      "learning_rate": 7.680000000000001e-06,
      "loss": 1.6468,
      "step": 200
    },
    {
      "epoch": 0.013115900843789621,
      "grad_norm": 3.3587300777435303,
      "learning_rate": 1.168e-05,
      "loss": 1.5031,
      "step": 300
    },
    {
      "epoch": 0.017487867791719496,
      "grad_norm": 4.014050483703613,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 1.4274,
      "step": 400
    },
    {
      "epoch": 0.021859834739649368,
      "grad_norm": 3.847578525543213,
      "learning_rate": 1.968e-05,
      "loss": 1.2749,
      "step": 500
    },
    {
      "epoch": 0.026231801687579243,
      "grad_norm": 4.71135950088501,
      "learning_rate": 1.999990998638051e-05,
      "loss": 1.1425,
      "step": 600
    },
    {
      "epoch": 0.030603768635509114,
      "grad_norm": 6.190884113311768,
      "learning_rate": 1.9999607957778192e-05,
      "loss": 1.1691,
      "step": 700
    },
    {
      "epoch": 0.03497573558343899,
      "grad_norm": 5.83561372756958,
      "learning_rate": 1.9999093239983835e-05,
      "loss": 1.1186,
      "step": 800
    },
    {
      "epoch": 0.039347702531368864,
      "grad_norm": 7.208166599273682,
      "learning_rate": 1.999836584394535e-05,
      "loss": 1.0763,
      "step": 900
    },
    {
      "epoch": 0.043719669479298735,
      "grad_norm": 7.141864776611328,
      "learning_rate": 1.9997425785134274e-05,
      "loss": 1.0176,
      "step": 1000
    },
    {
      "epoch": 0.04809163642722861,
      "grad_norm": 7.534890651702881,
      "learning_rate": 1.9996273083545428e-05,
      "loss": 1.0562,
      "step": 1100
    },
    {
      "epoch": 0.052463603375158485,
      "grad_norm": 6.693612098693848,
      "learning_rate": 1.9994907763696486e-05,
      "loss": 1.0399,
      "step": 1200
    },
    {
      "epoch": 0.05683557032308836,
      "grad_norm": 6.1151018142700195,
      "learning_rate": 1.9993329854627465e-05,
      "loss": 0.9949,
      "step": 1300
    },
    {
      "epoch": 0.06120753727101823,
      "grad_norm": 7.88855504989624,
      "learning_rate": 1.9991539389900108e-05,
      "loss": 1.0239,
      "step": 1400
    },
    {
      "epoch": 0.0655795042189481,
      "grad_norm": 8.206019401550293,
      "learning_rate": 1.998953640759715e-05,
      "loss": 0.9995,
      "step": 1500
    },
    {
      "epoch": 0.06995147116687798,
      "grad_norm": 6.775146484375,
      "learning_rate": 1.998732095032153e-05,
      "loss": 0.9839,
      "step": 1600
    },
    {
      "epoch": 0.07432343811480785,
      "grad_norm": 7.5768632888793945,
      "learning_rate": 1.9984893065195482e-05,
      "loss": 0.9781,
      "step": 1700
    },
    {
      "epoch": 0.07869540506273773,
      "grad_norm": 9.537776947021484,
      "learning_rate": 1.998225280385952e-05,
      "loss": 0.9758,
      "step": 1800
    },
    {
      "epoch": 0.0830673720106676,
      "grad_norm": 9.386397361755371,
      "learning_rate": 1.997940022247135e-05,
      "loss": 0.9471,
      "step": 1900
    },
    {
      "epoch": 0.08743933895859747,
      "grad_norm": 9.763877868652344,
      "learning_rate": 1.9976335381704677e-05,
      "loss": 0.9256,
      "step": 2000
    },
    {
      "epoch": 0.09181130590652735,
      "grad_norm": 11.428682327270508,
      "learning_rate": 1.9973058346747904e-05,
      "loss": 0.9403,
      "step": 2100
    },
    {
      "epoch": 0.09618327285445721,
      "grad_norm": 9.829697608947754,
      "learning_rate": 1.9969605128673486e-05,
      "loss": 0.9506,
      "step": 2200
    },
    {
      "epoch": 0.10055523980238709,
      "grad_norm": 9.217208862304688,
      "learning_rate": 1.9965906039074102e-05,
      "loss": 0.9838,
      "step": 2300
    },
    {
      "epoch": 0.10492720675031697,
      "grad_norm": 10.078974723815918,
      "learning_rate": 1.9961994977114165e-05,
      "loss": 0.9553,
      "step": 2400
    },
    {
      "epoch": 0.10929917369824683,
      "grad_norm": 7.263416290283203,
      "learning_rate": 1.995787202598099e-05,
      "loss": 0.9294,
      "step": 2500
    },
    {
      "epoch": 0.11367114064617671,
      "grad_norm": 9.018351554870605,
      "learning_rate": 1.9953537273368743e-05,
      "loss": 0.8937,
      "step": 2600
    },
    {
      "epoch": 0.11804310759410659,
      "grad_norm": 9.572131156921387,
      "learning_rate": 1.9948990811476524e-05,
      "loss": 0.9603,
      "step": 2700
    },
    {
      "epoch": 0.12241507454203646,
      "grad_norm": 10.160879135131836,
      "learning_rate": 1.9944232737006463e-05,
      "loss": 0.9562,
      "step": 2800
    },
    {
      "epoch": 0.12678704148996633,
      "grad_norm": 10.617703437805176,
      "learning_rate": 1.993926315116163e-05,
      "loss": 0.9163,
      "step": 2900
    },
    {
      "epoch": 0.1311590084378962,
      "grad_norm": 11.668383598327637,
      "learning_rate": 1.9934082159643888e-05,
      "loss": 0.9177,
      "step": 3000
    },
    {
      "epoch": 0.1355309753858261,
      "grad_norm": 10.02629566192627,
      "learning_rate": 1.9928689872651646e-05,
      "loss": 0.9062,
      "step": 3100
    },
    {
      "epoch": 0.13990294233375597,
      "grad_norm": 10.972166061401367,
      "learning_rate": 1.9923086404877518e-05,
      "loss": 0.8717,
      "step": 3200
    },
    {
      "epoch": 0.14427490928168582,
      "grad_norm": 8.960750579833984,
      "learning_rate": 1.9917271875505882e-05,
      "loss": 0.8975,
      "step": 3300
    },
    {
      "epoch": 0.1486468762296157,
      "grad_norm": 8.867860794067383,
      "learning_rate": 1.9911246408210337e-05,
      "loss": 0.9225,
      "step": 3400
    },
    {
      "epoch": 0.15301884317754558,
      "grad_norm": 8.028216361999512,
      "learning_rate": 1.9905010131151086e-05,
      "loss": 0.9123,
      "step": 3500
    },
    {
      "epoch": 0.15739081012547546,
      "grad_norm": 11.613485336303711,
      "learning_rate": 1.9898563176972205e-05,
      "loss": 0.889,
      "step": 3600
    },
    {
      "epoch": 0.16176277707340533,
      "grad_norm": 10.015555381774902,
      "learning_rate": 1.9891905682798814e-05,
      "loss": 0.8922,
      "step": 3700
    },
    {
      "epoch": 0.1661347440213352,
      "grad_norm": 11.672995567321777,
      "learning_rate": 1.9885037790234172e-05,
      "loss": 0.8777,
      "step": 3800
    },
    {
      "epoch": 0.17050671096926506,
      "grad_norm": 16.13541030883789,
      "learning_rate": 1.987795964535666e-05,
      "loss": 0.8798,
      "step": 3900
    },
    {
      "epoch": 0.17487867791719494,
      "grad_norm": 10.802135467529297,
      "learning_rate": 1.9870671398716667e-05,
      "loss": 0.8758,
      "step": 4000
    },
    {
      "epoch": 0.17925064486512482,
      "grad_norm": 11.865453720092773,
      "learning_rate": 1.9863249225983644e-05,
      "loss": 0.8852,
      "step": 4100
    },
    {
      "epoch": 0.1836226118130547,
      "grad_norm": 8.895956993103027,
      "learning_rate": 1.9855543342410312e-05,
      "loss": 0.8845,
      "step": 4200
    },
    {
      "epoch": 0.18799457876098458,
      "grad_norm": 12.080148696899414,
      "learning_rate": 1.9847627833863726e-05,
      "loss": 0.8739,
      "step": 4300
    },
    {
      "epoch": 0.19236654570891443,
      "grad_norm": 12.855257034301758,
      "learning_rate": 1.9839502868704804e-05,
      "loss": 0.9105,
      "step": 4400
    },
    {
      "epoch": 0.1967385126568443,
      "grad_norm": 12.652515411376953,
      "learning_rate": 1.983116861974955e-05,
      "loss": 0.8822,
      "step": 4500
    },
    {
      "epoch": 0.20111047960477418,
      "grad_norm": 9.776187896728516,
      "learning_rate": 1.9822625264265373e-05,
      "loss": 0.8788,
      "step": 4600
    },
    {
      "epoch": 0.20548244655270406,
      "grad_norm": 10.386506080627441,
      "learning_rate": 1.981387298396734e-05,
      "loss": 0.8915,
      "step": 4700
    },
    {
      "epoch": 0.20985441350063394,
      "grad_norm": 11.041513442993164,
      "learning_rate": 1.980491196501429e-05,
      "loss": 0.8269,
      "step": 4800
    },
    {
      "epoch": 0.21422638044856382,
      "grad_norm": 11.690045356750488,
      "learning_rate": 1.9795742398004887e-05,
      "loss": 0.8615,
      "step": 4900
    },
    {
      "epoch": 0.21859834739649367,
      "grad_norm": 11.522521018981934,
      "learning_rate": 1.9786364477973556e-05,
      "loss": 0.8505,
      "step": 5000
    },
    {
      "epoch": 0.22297031434442355,
      "grad_norm": 10.793797492980957,
      "learning_rate": 1.9776778404386333e-05,
      "loss": 0.8402,
      "step": 5100
    },
    {
      "epoch": 0.22734228129235343,
      "grad_norm": 12.906719207763672,
      "learning_rate": 1.9766984381136646e-05,
      "loss": 0.848,
      "step": 5200
    },
    {
      "epoch": 0.2317142482402833,
      "grad_norm": 12.762959480285645,
      "learning_rate": 1.975698261654095e-05,
      "loss": 0.8705,
      "step": 5300
    },
    {
      "epoch": 0.23608621518821318,
      "grad_norm": 12.861395835876465,
      "learning_rate": 1.9746773323334297e-05,
      "loss": 0.8514,
      "step": 5400
    },
    {
      "epoch": 0.24045818213614306,
      "grad_norm": 11.073432922363281,
      "learning_rate": 1.9736356718665845e-05,
      "loss": 0.8437,
      "step": 5500
    },
    {
      "epoch": 0.2448301490840729,
      "grad_norm": 10.285553932189941,
      "learning_rate": 1.97257330240942e-05,
      "loss": 0.814,
      "step": 5600
    },
    {
      "epoch": 0.2492021160320028,
      "grad_norm": 12.75650405883789,
      "learning_rate": 1.971490246558272e-05,
      "loss": 0.8206,
      "step": 5700
    },
    {
      "epoch": 0.25357408297993267,
      "grad_norm": 10.482443809509277,
      "learning_rate": 1.9703865273494715e-05,
      "loss": 0.8653,
      "step": 5800
    },
    {
      "epoch": 0.2579460499278625,
      "grad_norm": 10.30123233795166,
      "learning_rate": 1.9692621682588527e-05,
      "loss": 0.8819,
      "step": 5900
    },
    {
      "epoch": 0.2623180168757924,
      "grad_norm": 11.828554153442383,
      "learning_rate": 1.9681171932012562e-05,
      "loss": 0.858,
      "step": 6000
    },
    {
      "epoch": 0.2666899838237223,
      "grad_norm": 15.310965538024902,
      "learning_rate": 1.966951626530019e-05,
      "loss": 0.8345,
      "step": 6100
    },
    {
      "epoch": 0.2710619507716522,
      "grad_norm": 17.455137252807617,
      "learning_rate": 1.965765493036456e-05,
      "loss": 0.8606,
      "step": 6200
    },
    {
      "epoch": 0.27543391771958203,
      "grad_norm": 11.100112915039062,
      "learning_rate": 1.9645588179493343e-05,
      "loss": 0.8078,
      "step": 6300
    },
    {
      "epoch": 0.27980588466751194,
      "grad_norm": 10.63472843170166,
      "learning_rate": 1.9633316269343342e-05,
      "loss": 0.8244,
      "step": 6400
    },
    {
      "epoch": 0.2841778516154418,
      "grad_norm": 12.491615295410156,
      "learning_rate": 1.9620839460935062e-05,
      "loss": 0.8188,
      "step": 6500
    },
    {
      "epoch": 0.28854981856337164,
      "grad_norm": 11.909257888793945,
      "learning_rate": 1.9608158019647137e-05,
      "loss": 0.8206,
      "step": 6600
    },
    {
      "epoch": 0.29292178551130155,
      "grad_norm": 10.179409980773926,
      "learning_rate": 1.9595272215210688e-05,
      "loss": 0.833,
      "step": 6700
    },
    {
      "epoch": 0.2972937524592314,
      "grad_norm": 10.835114479064941,
      "learning_rate": 1.9582182321703596e-05,
      "loss": 0.8334,
      "step": 6800
    },
    {
      "epoch": 0.3016657194071613,
      "grad_norm": 13.062644958496094,
      "learning_rate": 1.956888861754466e-05,
      "loss": 0.8443,
      "step": 6900
    },
    {
      "epoch": 0.30603768635509115,
      "grad_norm": 9.42932415008545,
      "learning_rate": 1.9555527364332306e-05,
      "loss": 0.79,
      "step": 7000
    },
    {
      "epoch": 0.310409653303021,
      "grad_norm": 11.519729614257812,
      "learning_rate": 1.9541828922432984e-05,
      "loss": 0.808,
      "step": 7100
    },
    {
      "epoch": 0.3147816202509509,
      "grad_norm": 10.438860893249512,
      "learning_rate": 1.952792752818866e-05,
      "loss": 0.8298,
      "step": 7200
    },
    {
      "epoch": 0.31915358719888076,
      "grad_norm": 12.718544006347656,
      "learning_rate": 1.951382347727855e-05,
      "loss": 0.7855,
      "step": 7300
    },
    {
      "epoch": 0.32352555414681067,
      "grad_norm": 10.576994895935059,
      "learning_rate": 1.9499517069692348e-05,
      "loss": 0.8382,
      "step": 7400
    },
    {
      "epoch": 0.3278975210947405,
      "grad_norm": 14.030302047729492,
      "learning_rate": 1.9485008609723798e-05,
      "loss": 0.8037,
      "step": 7500
    },
    {
      "epoch": 0.3322694880426704,
      "grad_norm": 10.132806777954102,
      "learning_rate": 1.947029840596427e-05,
      "loss": 0.8249,
      "step": 7600
    },
    {
      "epoch": 0.3366414549906003,
      "grad_norm": 12.697778701782227,
      "learning_rate": 1.9455386771296155e-05,
      "loss": 0.8495,
      "step": 7700
    },
    {
      "epoch": 0.3410134219385301,
      "grad_norm": 8.888601303100586,
      "learning_rate": 1.944027402288625e-05,
      "loss": 0.7831,
      "step": 7800
    },
    {
      "epoch": 0.34538538888646003,
      "grad_norm": 11.738906860351562,
      "learning_rate": 1.9424960482178975e-05,
      "loss": 0.7964,
      "step": 7900
    },
    {
      "epoch": 0.3497573558343899,
      "grad_norm": 12.497314453125,
      "learning_rate": 1.9409446474889567e-05,
      "loss": 0.8055,
      "step": 8000
    },
    {
      "epoch": 0.3541293227823198,
      "grad_norm": 14.345617294311523,
      "learning_rate": 1.9393732330997123e-05,
      "loss": 0.8142,
      "step": 8100
    },
    {
      "epoch": 0.35850128973024964,
      "grad_norm": 9.76893424987793,
      "learning_rate": 1.9377818384737606e-05,
      "loss": 0.7758,
      "step": 8200
    },
    {
      "epoch": 0.3628732566781795,
      "grad_norm": 13.141094207763672,
      "learning_rate": 1.936170497459672e-05,
      "loss": 0.8055,
      "step": 8300
    },
    {
      "epoch": 0.3672452236261094,
      "grad_norm": 12.120361328125,
      "learning_rate": 1.9345392443302727e-05,
      "loss": 0.7927,
      "step": 8400
    },
    {
      "epoch": 0.37161719057403925,
      "grad_norm": 15.442092895507812,
      "learning_rate": 1.9328881137819134e-05,
      "loss": 0.7783,
      "step": 8500
    },
    {
      "epoch": 0.37598915752196915,
      "grad_norm": 12.52230453491211,
      "learning_rate": 1.931217140933733e-05,
      "loss": 0.805,
      "step": 8600
    },
    {
      "epoch": 0.380361124469899,
      "grad_norm": 8.388648986816406,
      "learning_rate": 1.9295263613269123e-05,
      "loss": 0.7945,
      "step": 8700
    },
    {
      "epoch": 0.38473309141782885,
      "grad_norm": 13.81252670288086,
      "learning_rate": 1.927815810923915e-05,
      "loss": 0.8036,
      "step": 8800
    },
    {
      "epoch": 0.38910505836575876,
      "grad_norm": 13.688431739807129,
      "learning_rate": 1.926085526107726e-05,
      "loss": 0.7692,
      "step": 8900
    },
    {
      "epoch": 0.3934770253136886,
      "grad_norm": 14.214418411254883,
      "learning_rate": 1.9243355436810764e-05,
      "loss": 0.807,
      "step": 9000
    }
  ],
  "logging_steps": 100,
  "max_steps": 68619,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.3247597436928e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
